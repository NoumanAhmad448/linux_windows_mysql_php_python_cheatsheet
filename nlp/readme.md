## Research Keywords | LLM keywords | Coding Challenges Keywords
```Always keep it at the top``` </br>
For reference [https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llm](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llm)
1. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Alanguage_modelling&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Alanguage_modelling&btnG=)
2. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Allm_agent&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Allm_agent&btnG=))
3. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Aevaluation&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Aevaluation&btnG=)
4. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:nlp](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:nlp)
5. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Acode_generation&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Acode_generation&btnG=)
6. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3ACode_translation&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3ACode_translation&btnG=)
7. label:code_debugging [not available but can be used in the future]
8. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:vision_language_models](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:vision_language_models)
9. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3AAdversarial_Attacks&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3AAdversarial_Attacks&btnG=)
10. [https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llm](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llm)
11. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:llms](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:llms)
12. 

## Strategies
1. Take a generic example(s) and show multiple model accuracies
2. show the accuracies changes over the time frames or input
3. Try to categories the work like linear loop and double loop and show their accuracies over the different models
4. Show the  ```Levenshtein similarity``` graph over differnt input threads
5. Show complexity over number of tokens which always increases with complexity.

## Graph Design Links Results
1. [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3ACode_translation&btnG=](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3ACode_translation&btnG=)
2. 

</br>```Always keep it at the top```


## NLP LLM Prompt Training Terminologies

|    |    |    ||
|------------|------------|------------|------------|
| *Finetuning method* | lora | freeze | freeze |
| *qlora* | 4 | 8 |
| *Rope Scalling* | Linear | Dynamic |
| *Booster* | flashattn2 | unsloth |linger |
| *Stage* | Supervised Fine Training |
| *Compute Type* | bf16 | fp16 |


## After training model to run model 
1. https://github.com/sgl-project/sglang
2. https://github.com/vllm-project/vllm%E3%80%90api
3. 


## During training of models
1. https://github.com/microsoft/DeepSpeed
2. https://github.com/unslothai/unsloth

## web ui developer
1. https://github.com/gradio-app/gradio
2. To develop command line apps
   ```
   setuptools and find_packages
   ```
3. 

## Search Models 
1. https://www.modelscope.cn/
2. https://modelers.cn/models
3. https://huggingface.co
4. 


# Terminologies
Large langauge models,NLP,code generation,LLM benchmarks,Eval benchmarks,Code Summarization,
In-Context Learning

## Companies
- Hugging face
- microsoft
- OPENAI
- Google
- meta


## Technical Terms
- Word2Vec
- GloVe
- Fine-tuning
- infilling
- Zero-shot learning is a prompt that has no examples
- One-shot has one example, and
- few-shot has more than one example.
- Codex: LLM by OPENAI
- Tokenization
- Stemming
- POS(part of speech)
- lemmatization

## NLP:
->TF_IDF,Bi-Gram and Tri-Gram,Bag of Words BOW,OneHotEncoding Text


## Hugging Face:
Text classification	assign a label to a given sequence of text	NLP	pipeline(task=“sentiment-analysis”)
Text generation	generate text given a prompt	NLP	pipeline(task=“text-generation”)
Summarization	generate a summary of a sequence of text or document	NLP	pipeline(task=“summarization”)

## python libraries
- Reading words in the email Enron_Emails_Dataset_Processed kmcluster
https://towardsdatascience.com/how-i-used-machine-learning-to-classify-emails-and-turn-them-into-insights-efed37c1e66
-  training eron emails over multiple models  KNeighborsClassifier,DecisionTreeClassifier,LogisticRegression
https://github.com/soliverc/Enron-Ham-Spam-Email-FIlter/blob/master/Enron%20HamSpam.ipynb
-  Network Construction python library
https://github.com/RutujChheda/Enron_Emails_Dataset_Processed/blob/main/Enron_Data_Normalization.ipynb
https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/notebook
https://www.kaggle.com/code/mfaaris/content-based-and-tensorflow-recommender-system/notebook

## Basic Requirement for every prompt
- Always put the variables in env file
- Use cprint of termcolor package instead python build in print
- Add a log file called error.log which include the only latest error message and delete all previous messages
- Bring always dynamic appraoch much diverse with API request handling etc
- Follow all rules when you save the file. A file must be runnable in any operating system
  
## All Research Papers
### Top Papers
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Llama%3A+Open+and+efficient+foundation+language+models&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=The+llama+3+herd+of+models&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Code+llama%3A+Open+foundation+models+for+code&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Pixtral+12B&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Qwen2.+5+Technical+Report&btnG=
- 

### 2025
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=odeElo%3A+Benchmarking+Competition-level+Code+Generation+of+LLMs+with+Human-comparable+Elo+Ratings&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=ExecRepoBench%3A+Multi-level+Executable+Code+Completion+Evaluation&btnG=
- 
### 2024
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Testgeneval%3A+A+real+world+unit+test+generation+and+test+completion+benchmark&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Cruxeval%3A+A+benchmark+for+code+reasoning%2C+understanding+and+execution&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=A+framework+for+evaluating+tool+support+for+co-evolution+of+modeling+languages%2C+tools+and+models&btnG=
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Evaluating+and+aligning+codellms+on+human+preference&btnG=
- 

### 2023
- [Self-taught optimizer (stop): Recursively self-improving code generation](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Self-taught+optimizer+%28stop%29%3A+Recursively+self-improving+code+generation&btnG=)

### 2022
- https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=Docprompting%3A+Generating+code+by+retrieving+the+docs&btnG=
